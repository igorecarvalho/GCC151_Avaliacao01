{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prova de PLN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igorecarvalho/.local/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from nlputils import lexical\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definição do diretorio dos corpus e criacao de uma lista com os nomes de cada arquivo dentro do diretorio\n",
    "corpora_path = '../data/corpora/'\n",
    "files_corpora = os.listdir(corpora_path)\n",
    "files_corpora = [d for d in files_corpora if d not in '.DS_Store']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação\tde\tuma\tbiblioteca\tde\tPLN,\tcom\trotinas\tde\tnormalização\ttextual\tdo\tnível\tlexical:\n",
    "- remoção\tde\tpontuação\n",
    "- remoção\tde\tacentos\n",
    "- remoção\tde\tstopwords\n",
    "- lowercase\n",
    "- stemming\n",
    "- tokenizar\ttexto\tem\tsentenças\n",
    "- tokenizer\ttexto\tem\tpalavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chamada da bibioteca de preprocessamento\n",
    "normalizer = lexical.Preprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cada\tcórpus\tdeve\testar\tem\tum\tdiretório\tespecífico e\tconter,\tpelo\tmenos\t500 textos\tcada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538\n",
      "664\n"
     ]
    }
   ],
   "source": [
    "#criacao de um dicionario que ira armazenar cada corpus em uma chave\n",
    "sentences_dic = {}\n",
    "all_files = []\n",
    "for corpus in files_corpora:\n",
    "    files = [os.path.join(corpora_path + corpus, f) \\\n",
    "             for f in os.listdir(corpora_path + corpus) \\\n",
    "             if os.path.isfile(os.path.join(corpora_path + corpus, f))]\n",
    "    #cada corpus tera mais 3 chaves para armazenar informacoes de trabalho\n",
    "    sentences_dic[corpus] = {'sentencas': [], 'tokens': [], 'tamanho': []}\n",
    "    \n",
    "    #adiciona todos os arquivos em uma unica lista independentemente do corpus\n",
    "    print(len(files))\n",
    "    all_files.extend(files)\n",
    "    \n",
    "    #para cada arquivo em um corpus sera extraido suas frases e armazenadas em cada linha de uma lista\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as text_file:\n",
    "            lines = text_file.readlines()\n",
    "            for line in lines:\n",
    "                if line != '\\n':\n",
    "                    #armazenamento das sentencas do arquivo como escritas originalmente\n",
    "                    sentences_dic[corpus]['sentencas'].append(line)\n",
    "\n",
    "                    #toda a sentenca sera escrita em letras minusculas\n",
    "                    line = normalizer.lowercase(line) \n",
    "                    #tokeniza as sentencas\n",
    "                    sentences = normalizer.tokenize_sentences(line)\n",
    "                    \n",
    "                    #remove as pontuacoes\n",
    "                    sentences = normalizer.remove_punctuation(sentences)\n",
    "                    \n",
    "                    #tokeniza as palavras de cada sentenca\n",
    "                    sentences = [normalizer.tokenize_words(sent) for sent in sentences]\n",
    "                    #remove os stopwords\n",
    "                    sentences = normalizer.remove_stopwords(sentences)\n",
    "                    \n",
    "                    #armazena cada sentenca em forma de tokens\n",
    "                    sentences_dic[corpus]['tokens'].append(sentences[0])\n",
    "                    #armazena o tamanho, em numero de palavras, de cada sentenca\n",
    "                    sentences_dic[corpus]['tamanho'].append(len(sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['animais', 'games'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizacao do Pandas para visualizao dos dados em forma de tabelas\n",
    "import pandas as pd\n",
    "\n",
    "#cracao de um dicionario que ira armazenar cada corpus em suas respectivas keys.\n",
    "dataframes_dic = {}\n",
    "for key in sentences_dic.keys():\n",
    "    #os corpus armazenados aqui estara em formato de DataFrame onde cada key sera uma coluna da tabela\n",
    "    dataframes_dic[key] = pd.DataFrame(sentences_dic[key], columns=['sentencas','tokens','tamanho'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentencas</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tamanho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dizem que fomos criados para amar e sermos ama...</td>\n",
       "      <td>[dizem, que, fomos, criados, para, amar, e, se...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E mais uma vez nosso cachorro nos vê com a toa...</td>\n",
       "      <td>[e, mais, uma, vez, nosso, cachorro, nos, vê, ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mudanças climáticas, a caça predatória, o desm...</td>\n",
       "      <td>[mudanças, climáticas, a, caça, predatória, o,...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mudanças climáticas, a caça predatória, o desm...</td>\n",
       "      <td>[mudanças, climáticas, a, caça, predatória, o,...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 comportamentos típicos dos gatosSe você tem...</td>\n",
       "      <td>[10, comportamentos, típicos, dos, gatosse, vo...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 curiosidades sobre nossos amigos coelhosHoj...</td>\n",
       "      <td>[10, curiosidades, sobre, nossos, amigos, coel...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Os cães estiveram próximos ao homem durante sé...</td>\n",
       "      <td>[os, cães, estiveram, próximos, ao, homem, dur...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3 perigos de humanizar um cãoUma tendência bas...</td>\n",
       "      <td>[3, perigos, de, humanizar, um, cãouma, tendên...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 propriedades do óleo de coco para cãesOs gra...</td>\n",
       "      <td>[3, propriedades, do, óleo, de, coco, para, cã...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Uma das maiores aves do planeta é pouco conhec...</td>\n",
       "      <td>[uma, das, maiores, aves, do, planeta, é, pouc...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentencas  \\\n",
       "0  Dizem que fomos criados para amar e sermos ama...   \n",
       "1  E mais uma vez nosso cachorro nos vê com a toa...   \n",
       "2  Mudanças climáticas, a caça predatória, o desm...   \n",
       "3  Mudanças climáticas, a caça predatória, o desm...   \n",
       "4  10 comportamentos típicos dos gatosSe você tem...   \n",
       "5  10 curiosidades sobre nossos amigos coelhosHoj...   \n",
       "6  Os cães estiveram próximos ao homem durante sé...   \n",
       "7  3 perigos de humanizar um cãoUma tendência bas...   \n",
       "8  3 propriedades do óleo de coco para cãesOs gra...   \n",
       "9  Uma das maiores aves do planeta é pouco conhec...   \n",
       "\n",
       "                                              tokens  tamanho  \n",
       "0  [dizem, que, fomos, criados, para, amar, e, se...       14  \n",
       "1  [e, mais, uma, vez, nosso, cachorro, nos, vê, ...       19  \n",
       "2  [mudanças, climáticas, a, caça, predatória, o,...       16  \n",
       "3  [mudanças, climáticas, a, caça, predatória, o,...       16  \n",
       "4  [10, comportamentos, típicos, dos, gatosse, vo...       35  \n",
       "5  [10, curiosidades, sobre, nossos, amigos, coel...       12  \n",
       "6  [os, cães, estiveram, próximos, ao, homem, dur...       12  \n",
       "7  [3, perigos, de, humanizar, um, cãouma, tendên...       17  \n",
       "8  [3, propriedades, do, óleo, de, coco, para, cã...       25  \n",
       "9  [uma, das, maiores, aves, do, planeta, é, pouc...        9  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_dic['animais'].head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentencas</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tamanho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Historiador carioca que trabalha como Redator ...</td>\n",
       "      <td>[historiador, carioca, que, trabalha, como, re...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apesar de escrever sobre todo tipo de coisa pa...</td>\n",
       "      <td>[apesar, de, escrever, sobre, todo, tipo, de, ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Battle Royale de Battlefield 5, Firestorm rece...</td>\n",
       "      <td>[battle, royale, de, battlefield, 5, firestorm...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Borderlands 3 vem aí; veja trailer de gameplay...</td>\n",
       "      <td>[borderlands, 3, vem, aí, veja, trailer, de, g...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cinco programas para limpar o PC e deixar seu ...</td>\n",
       "      <td>[cinco, programas, para, limpar, o, pc, e, dei...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cinco programas para ouvir música grátis no co...</td>\n",
       "      <td>[cinco, programas, para, ouvir, música, grátis...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Clash Royale: cinco coisas que você nunca deve...</td>\n",
       "      <td>[clash, royale, cinco, coisas, que, você, nunc...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Clash Royale recebe balanceamento de março; ve...</td>\n",
       "      <td>[clash, royale, recebe, balanceamento, de, mar...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mais de 100 mil jogadores já foram banidos do ...</td>\n",
       "      <td>[mais, de, 100, mil, jogadores, já, foram, ban...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Angry Birds, Candy Crush e mais; 10 jogos clás...</td>\n",
       "      <td>[angry, birds, candy, crush, e, mais, 10, jogo...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentencas  \\\n",
       "0  Historiador carioca que trabalha como Redator ...   \n",
       "1  Apesar de escrever sobre todo tipo de coisa pa...   \n",
       "2  Battle Royale de Battlefield 5, Firestorm rece...   \n",
       "3  Borderlands 3 vem aí; veja trailer de gameplay...   \n",
       "4  Cinco programas para limpar o PC e deixar seu ...   \n",
       "5  Cinco programas para ouvir música grátis no co...   \n",
       "6  Clash Royale: cinco coisas que você nunca deve...   \n",
       "7  Clash Royale recebe balanceamento de março; ve...   \n",
       "8  Mais de 100 mil jogadores já foram banidos do ...   \n",
       "9  Angry Birds, Candy Crush e mais; 10 jogos clás...   \n",
       "\n",
       "                                              tokens  tamanho  \n",
       "0  [historiador, carioca, que, trabalha, como, re...       11  \n",
       "1  [apesar, de, escrever, sobre, todo, tipo, de, ...       29  \n",
       "2  [battle, royale, de, battlefield, 5, firestorm...       51  \n",
       "3  [borderlands, 3, vem, aí, veja, trailer, de, g...       27  \n",
       "4  [cinco, programas, para, limpar, o, pc, e, dei...       17  \n",
       "5  [cinco, programas, para, ouvir, música, grátis...       42  \n",
       "6  [clash, royale, cinco, coisas, que, você, nunc...       21  \n",
       "7  [clash, royale, recebe, balanceamento, de, mar...       50  \n",
       "8  [mais, de, 100, mil, jogadores, já, foram, ban...       49  \n",
       "9  [angry, birds, candy, crush, e, mais, 10, jogo...       65  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_dic['games'].head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criacao de uma \"bag\" de palavras dos tokens para cada corpus\n",
    "dic_words = {}\n",
    "for key in sentences_dic.keys():\n",
    "    words_corpus = []\n",
    "    for sentence in sentences_dic[key]['tokens']:\n",
    "        no_stopwords_sentence = normalizer.remove_stopwords(sentence)\n",
    "        words_corpus.extend(no_stopwords_sentence)\n",
    "    #adiciona ao dicionario de palavras o corpus de tokens\n",
    "    dic_words[key] = words_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilização do sklearn para facilitar a contagem de palavras com auxilio da bibioteca CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#função que realiza a contagem das palavras e retona 3 lista:\n",
    "# - Lista de frenquencia de palavras(words_freq)\n",
    "# - Lista das 20 palavras mais frequentes(most_freq_words)\n",
    "# - Lista das 20 palavras menos frequentes(less_freq_words)\n",
    "def words_frequency(token_corpus):\n",
    "    vec = CountVectorizer().fit(token_corpus)\n",
    "\n",
    "    #Here we get a Bag of Word model that has cleaned the text, removing non-aphanumeric characters and stop words.\n",
    "    bag_of_words = vec.transform(token_corpus)\n",
    "\n",
    "    #sum_words is a vector that contains the sum of each word occurrence in all texts in the corpus. \n",
    "    #In other words, we are adding the elements for each column of bag_of_words matrix.\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    most_freq_words = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    less_freq_words = sorted(words_freq, key = lambda x: x[1])\n",
    "    \n",
    "    return words_freq, most_freq_words[:20], less_freq_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicionario que ira armazenar as inforções das palavras em cada corpus\n",
    "word_analysis = {}\n",
    "\n",
    "#dicionario de dataFrame das palavras listadas no dicionario word_analysis\n",
    "word_df = {}\n",
    "\n",
    "for key in dic_words.keys():\n",
    "    #as listas retornadas pela função words_frequency é uma lista de lista que indica a palavra juntamente com sua\n",
    "    #contagem de aparição no texto\n",
    "    words_freq, most_freq_words, less_freq_words = words_frequency(dic_words[key])\n",
    "    \n",
    "    word_analysis[key] = {'Palavra': [],'Quantidade': [], 'Tamanho': []}\n",
    "    \n",
    "    #por palavra retornada da lista armazeno no dicionario separadamente a palavra, sua quantidade e seu tamanho\n",
    "    for wd_qt in words_freq:\n",
    "        word_analysis[key]['Palavra'].append(wd_qt[0])\n",
    "        word_analysis[key]['Quantidade'].append(wd_qt[1])\n",
    "        word_analysis[key]['Tamanho'].append(len(wd_qt[0]))\n",
    "\n",
    "    word_df[key] = pd.DataFrame(word_analysis[key], columns=['Palavra','Quantidade','Tamanho'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavra</th>\n",
       "      <th>Quantidade</th>\n",
       "      <th>Tamanho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dizem</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fomos</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>criados</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amar</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sermos</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amados</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanto</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>como</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>animais</td>\n",
       "      <td>189</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mais</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Palavra  Quantidade  Tamanho\n",
       "0    dizem           3        5\n",
       "1    fomos           1        5\n",
       "2  criados           2        7\n",
       "3     amar           1        4\n",
       "4   sermos           1        6\n",
       "5   amados           1        6\n",
       "6    tanto           5        5\n",
       "7     como           7        4\n",
       "8  animais         189        7\n",
       "9     mais          30        4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df['animais'].head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavra</th>\n",
       "      <th>Quantidade</th>\n",
       "      <th>Tamanho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>historiador</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>carioca</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trabalha</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>redator</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>editor</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vários</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>anos</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apesar</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>escrever</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sobre</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Palavra  Quantidade  Tamanho\n",
       "0  historiador           1       11\n",
       "1      carioca           3        7\n",
       "2     trabalha           1        8\n",
       "3      redator           1        7\n",
       "4       editor           3        6\n",
       "5       vários           7        6\n",
       "6         anos          25        4\n",
       "7       apesar           5        6\n",
       "8     escrever           1        8\n",
       "9        sobre          22        5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df['games'].head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As\tseguintes\testatísticas\tdevem ser\tapresentadas, por\tcórpus:\n",
    "- 20\tpalavras\tmais\tfrequentes\n",
    "- 20\tpalavras\tmenos\tfrequentes\n",
    "- Tamanho\tmédio\tdas\tpalavras\n",
    "- Tamanho\tmédio\tdas\tsentenças,\tem\tnúmero\tde\tpalavras\n",
    "- Outras\tduas\testatísticas\tque\tachar\tinteressante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicionario para armazenar as estatisticas sobre os corpus\n",
    "corpus_analysis = {}\n",
    "\n",
    "#dicionario que servirá para armazenar dataframes de estatisticas de cada corpus\n",
    "analysis_df = {}\n",
    "for corpus in sentences_dic.keys():\n",
    "    #as listas retornadas pela função words_frequency é uma lista de lista que indica a palavra juntamente com sua\n",
    "    #contagem de aparição no texto\n",
    "    words_freq, mfw, lfw = words_frequency(dic_words[corpus])\n",
    "    \n",
    "    #dicionario de dicionario, onde cada corpus terá suas proprioas estatisticas armazenadas\n",
    "    corpus_analysis[corpus] = {'Palavras Mais Frequentes(20)': [], 'Palavras Menos Frequentes(20)': [], \n",
    "                               'Tamanho medio das Palavras': [], 'Numero de sentencas': [], \n",
    "                               'Tamanho medio das sentencas': [], 'Word2Vec': []}\n",
    "    \n",
    "    #separa da lista de lista somente as palavra, armazena um vetor e salva no dicionario\n",
    "    most_freq_words = []\n",
    "    for w in mfw:\n",
    "        most_freq_words.append(w[0])\n",
    "    corpus_analysis[corpus]['Palavras Mais Frequentes(20)'].append(most_freq_words)\n",
    "    \n",
    "    #separa da lista de lista somente as palavra, armazena um vetor e salva no dicionario\n",
    "    less_freq_words = []\n",
    "    for w in lfw:\n",
    "        less_freq_words.append(w[0])\n",
    "    corpus_analysis[corpus]['Palavras Menos Frequentes(20)'].append(less_freq_words)\n",
    "    \n",
    "    #com uso do dataframe word_df é calculada a media do tamanho de todas as palavras do corpus adicionado ao\n",
    "    #dicionario de estatistica\n",
    "    words_mean = word_df[corpus]['Tamanho'].mean()\n",
    "    corpus_analysis[corpus]['Tamanho medio das Palavras'].append(words_mean)\n",
    "    \n",
    "    #adiciona o numero de sentencas ao dicionario de estatisticas\n",
    "    corpus_analysis[corpus]['Numero de sentencas'].append(len(sentences_dic[corpus]['sentencas']))\n",
    "    \n",
    "    #com uso do dataframe word_df é calculada a media do tamanho de todas as sentencas do corpus adicionado ao\n",
    "    #dicionario de estatistica\n",
    "    sentences_mean = dataframes_dic[corpus]['tamanho'].mean()\n",
    "    corpus_analysis[corpus]['Tamanho medio das sentencas'].append(sentences_mean)\n",
    "    \n",
    "    #criacao do dataframe com os dados estatisticos adicinados ao dicinario corpus_analysis\n",
    "    analysis_df[corpus] = pd.DataFrame(corpus_analysis[corpus], columns=['Palavras Mais Frequentes(20)',\n",
    "                                                                        'Palavras Menos Frequentes(20)',\n",
    "                                                                       'Tamanho medio das Palavras',\n",
    "                                                                       'Numero de sentencas',\n",
    "                                                                       'Tamanho medio das sentencas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estátisticas do corpus animais\n",
      "20 palavras mais frequentes: \n",
      " [['animais', 'que', 'os', 'estimação', 'cães', 'animal', 'um', 'seu', 'gatos', 'ser', 'uma', 'cão', 'se', 'sobre', 'espécies', 'podem', 'sua', 'espécie', 'não', 'têm']]\n",
      "20 palavras menos frequentes: \n",
      " [['fomos', 'amar', 'sermos', 'amados', 'típicos', 'gatosse', 'observou', 'estranhas', 'preocupe', 'achando', 'louco', 'coelhoshoje', 'oryctolagus', 'cuniculus', 'servindo', 'cãouma', 'tendência', 'difundida', 'propriedades', 'ligados']]\n",
      "Tamanho medio das Palavras:  [7.699177438307873]\n",
      "Numero de sentencas:  [528]\n",
      "Tamanho medio das sentencas:  [27.40530303030303]\n",
      "\n",
      "Estátisticas do corpus games\n",
      "20 palavras mais frequentes: \n",
      " [['2019', 'atualizado', 'jogo', '04', '2018', 'of', 'game', 'jogos', 'xbox', 'pc', 'android', 'one', 'ps4', 'novo', '2017', 'royale', 'um', 'ios', 'the', 'iphone']]\n",
      "20 palavras menos frequentes: \n",
      " [['historiador', 'trabalha', 'redator', 'escrever', 'predileção', 'temas', 'ligados', 'literatura', 'trailerconteúdo', 'marçopor', '15h07', '14t180752018zdivulgação', 'artsbattlefield', 'aí', 'anúncionovo', 'gearbox', 'mundos', 'cooperativa', 'limpar', 'rápidoquer']]\n",
      "Tamanho medio das Palavras:  [8.146819239720713]\n",
      "Numero de sentencas:  [664]\n",
      "Tamanho medio das sentencas:  [40.49698795180723]\n"
     ]
    }
   ],
   "source": [
    "#exibe as estatisticas para todos os corpus\n",
    "for corpus in corpus_analysis.keys():\n",
    "    print(\"\\nEstátisticas do corpus\", corpus)\n",
    "    print(\"20 palavras mais frequentes: \\n\", corpus_analysis[corpus]['Palavras Mais Frequentes(20)'])\n",
    "    print(\"20 palavras menos frequentes: \\n\", corpus_analysis[corpus]['Palavras Menos Frequentes(20)'])\n",
    "    print(\"Tamanho medio das Palavras: \", corpus_analysis[corpus]['Tamanho medio das Palavras'])\n",
    "    print(\"Numero de sentencas: \", corpus_analysis[corpus]['Numero de sentencas'])\n",
    "    print(\"Tamanho medio das sentencas: \", corpus_analysis[corpus]['Tamanho medio das sentencas'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavras Mais Frequentes(20)</th>\n",
       "      <th>Palavras Menos Frequentes(20)</th>\n",
       "      <th>Tamanho medio das Palavras</th>\n",
       "      <th>Numero de sentencas</th>\n",
       "      <th>Tamanho medio das sentencas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[animais, que, os, estimação, cães, animal, um...</td>\n",
       "      <td>[fomos, amar, sermos, amados, típicos, gatosse...</td>\n",
       "      <td>7.699177</td>\n",
       "      <td>528</td>\n",
       "      <td>27.405303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Palavras Mais Frequentes(20)  \\\n",
       "0  [animais, que, os, estimação, cães, animal, um...   \n",
       "\n",
       "                       Palavras Menos Frequentes(20)  \\\n",
       "0  [fomos, amar, sermos, amados, típicos, gatosse...   \n",
       "\n",
       "   Tamanho medio das Palavras  Numero de sentencas  \\\n",
       "0                    7.699177                  528   \n",
       "\n",
       "   Tamanho medio das sentencas  \n",
       "0                    27.405303  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exibe o dataframe de estatisticas para os corpus\n",
    "analysis_df['animais'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavras Mais Frequentes(20)</th>\n",
       "      <th>Palavras Menos Frequentes(20)</th>\n",
       "      <th>Tamanho medio das Palavras</th>\n",
       "      <th>Numero de sentencas</th>\n",
       "      <th>Tamanho medio das sentencas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2019, atualizado, jogo, 04, 2018, of, game, j...</td>\n",
       "      <td>[historiador, trabalha, redator, escrever, pre...</td>\n",
       "      <td>8.146819</td>\n",
       "      <td>664</td>\n",
       "      <td>40.496988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Palavras Mais Frequentes(20)  \\\n",
       "0  [2019, atualizado, jogo, 04, 2018, of, game, j...   \n",
       "\n",
       "                       Palavras Menos Frequentes(20)  \\\n",
       "0  [historiador, trabalha, redator, escrever, pre...   \n",
       "\n",
       "   Tamanho medio das Palavras  Numero de sentencas  \\\n",
       "0                    8.146819                  664   \n",
       "\n",
       "   Tamanho medio das sentencas  \n",
       "0                    40.496988  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df['games'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização\tdos\tcorpora,\tcom\tvistas\tà\tcriação\tde\tdois\tmodelos,\ta\tsaber,\tWord2Vec\te\tDoc2Vec.\n",
    "- Para\tcada\tcórpus, será criado\tum\tmodelo\tWord2Vec\n",
    "- Para\ttodos\tos\tcorpora,\tapenas\tum\tmodelo\tDoc2Vec\tserá criado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para\tcada\tcórpus, será criado\tum\tmodelo\tWord2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importacao das bibiotecas w2vec e d2vec\n",
    "from gensim.models import Word2Vec, Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para cada corpus é adicionado em seu dicionario um modelo de word2vec \n",
    "for corpus in corpus_analysis.keys():\n",
    "    sentence_tokens = sentences_dic[corpus]['tokens']\n",
    "    w2vmodel = Word2Vec(sentences=sentence_tokens, size=300,min_count=5, workers=4, window=2)\n",
    "    corpus_analysis[corpus]['Word2Vec'] = w2vmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para todos os corpora, apenas um modelo Doc2Vec será criado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- preparação dos documentos em uma lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1202\n"
     ]
    }
   ],
   "source": [
    "#lista que recebera cada documentos de todos os corpora em cada uma de suas posicoes\n",
    "all_documents = []\n",
    "for file in all_files:\n",
    "    with open(file, 'r', encoding='utf-8') as text_file:\n",
    "        document = ' '.join(text_file.readlines())\n",
    "        document = normalizer.lowercase(document)\n",
    "        document_tokens = normalizer.tokenize_words(document)\n",
    "        all_documents.append(document_tokens)\n",
    "print(\"Number of documents: {}\".format(len(all_documents)))\n",
    "\n",
    "#enumera os documentos taggeando-os e salvando-os em tagged_documents\n",
    "tagged_documents = [TaggedDocument(words=d, tags=[str(i)]) for i, d in enumerate(all_documents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- treino do modelo de doc2vec para todos os arquivos do corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treina um modelo de doc2vec apartir da lista de documentos tageados\n",
    "d2vmodel = Doc2Vec(tagged_documents, vector_size=20, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso\tdos\tmodelos\tgerados\n",
    "\n",
    "- Uso\tdo\tWord2Vec\n",
    "\n",
    "#### Dada\tuma\tpalavra w1 de\tum\tcórpus,\tquais\tas\t10\tpalavras\tmais\tsimilares a\tw1?\n",
    "1. Exemplifique\t com\t três\t palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Corpus animais\n",
      "\n",
      "As  10  palavras mais similares a  água sao:\n",
      "[('é', 0.6974412202835083), ('animais', 0.6717917919158936), ('que', 0.6712997555732727), ('ter', 0.6628237962722778), ('cães', 0.6588107347488403), ('se', 0.6579687595367432), ('ser', 0.6571846008300781), ('um', 0.6555092334747314), ('os', 0.6506297588348389), ('pessoas', 0.6484097838401794)]\n",
      "\n",
      "As  10  palavras mais similares a  alimentação sao:\n",
      "[('é', 0.6502914428710938), ('que', 0.6354523301124573), ('estimação', 0.6247636675834656), ('os', 0.6142265796661377), ('animais', 0.613961398601532), ('cães', 0.6133837699890137), ('ter', 0.598894476890564), ('têm', 0.5968915820121765), ('o', 0.5956196784973145), ('ser', 0.584426999092102)]\n",
      "\n",
      "As  10  palavras mais similares a  cuidados sao:\n",
      "[('é', 0.6932001113891602), ('os', 0.6896755695343018), ('animais', 0.6867575645446777), ('seu', 0.6654595136642456), ('estimação', 0.6654074192047119), ('têm', 0.6653927564620972), ('espécies', 0.6635383367538452), ('espécie', 0.6598745584487915), ('gatos', 0.6533156633377075), ('sobre', 0.64935702085495)]\n",
      "\n",
      "Corpus games\n",
      "\n",
      "As  10  palavras mais similares a  jogos sao:\n",
      "[('é', 0.9982384443283081), ('o', 0.9980262517929077), ('jogo', 0.9978657960891724), ('game', 0.9976832866668701), ('2018', 0.9975208044052124), ('a', 0.9974629878997803), ('2019', 0.997305691242218), ('android', 0.9972670078277588), ('atualizado', 0.9971047639846802), ('of', 0.9970136880874634)]\n",
      "\n",
      "As  10  palavras mais similares a  jogadores sao:\n",
      "[('é', 0.9977195262908936), ('o', 0.9974628686904907), ('jogo', 0.9971502423286438), ('jogos', 0.9967687129974365), ('game', 0.9967301487922668), ('2019', 0.9967015981674194), ('a', 0.9966185688972473), ('android', 0.9965063333511353), ('atualizado', 0.996483325958252), ('2018', 0.9963374733924866)]\n",
      "\n",
      "As  10  palavras mais similares a  online sao:\n",
      "[('é', 0.9964710474014282), ('o', 0.9959486722946167), ('game', 0.9955276846885681), ('2018', 0.9955081343650818), ('jogo', 0.9955062866210938), ('a', 0.9952885508537292), ('jogos', 0.9952590465545654), ('android', 0.9952505826950073), ('um', 0.9951798319816589), ('2019', 0.9951057434082031)]\n"
     ]
    }
   ],
   "source": [
    "#define a quantidade de palavras similares deseja buscar\n",
    "n_words = 10\n",
    "\n",
    "#palavras para encontrar similaridade de acordo com os modelos treinados com o word2vec\n",
    "test_word = [['água', 'alimentação', 'cuidados'],['jogos', 'jogadores', 'online']]\n",
    "\n",
    "cont = 0\n",
    "for corpus in corpus_analysis:\n",
    "    print(\"\\nCorpus\", corpus)\n",
    "    print(\"\\nAs \", n_words, \" palavras mais similares a \", test_word[cont][0], \"sao:\")\n",
    "    print(corpus_analysis[corpus]['Word2Vec'].wv.most_similar(test_word[cont][0], topn=n_words))\n",
    "    print(\"\\nAs \", n_words, \" palavras mais similares a \", test_word[cont][1], \"sao:\")\n",
    "    print(corpus_analysis[corpus]['Word2Vec'].wv.most_similar(test_word[cont][1], topn=n_words))\n",
    "    print(\"\\nAs \", n_words, \" palavras mais similares a \", test_word[cont][2], \"sao:\")\n",
    "    print(corpus_analysis[corpus]['Word2Vec'].wv.most_similar(test_word[cont][2], topn=n_words))\n",
    "    cont = cont+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. discuta\t como\t poderia\tmelhorar\t os\tresultados.\tPense\tno\tnível\tda\tmorfologia\tou\toutro\tdo\tPLN.\n",
    "\n",
    "Para melhorar o resultado do word2vec é utilizar um corpus maior, com mais palavras, outros meios tambem é melhorar a normatização dos dados removendo stopwords, colocar as palavras em minusculas e utiliar uma boa fonte para extração dos corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Tentar\talguma\tabordagem\tpara\tcomparar\tdois\tdocumentos\tdiferentes\tutilizando\tos\tvetores\tdo\tWord2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uso\tdo\tDoc2Vec\n",
    "\n",
    "#### Dados\tos\tdocumentos\t(textos) de\tcorporas\tdiferentes,\tutilize\tos\tvetores\tpara encontrar\tos\tdocumentos\tmais\tsimilares\n",
    "\n",
    "1. Exemplifique\tcom\ttrês\tdocumentos\te\tdiscuta\tos resultados.\tAo\tser\tver, foram\tbons?\tOs\tdocumentos\trealmente\tsão\tparecidos?\tO\tque\tpoderia\t ser\tfeito\tpara\tmelhorar os\tresultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "documentos similares ao documento:  ../data/corpora/animais/https:--meusanimais_com_br-o-que-o-rabo-do-gato-esta-dizendo-.txt\n",
      "../data/corpora/animais/https:--meusanimais_com_br-o-sonho-dos-caes-voce-ja-parou-para-observar-como-os-cachorros-dormem-.txt\n",
      "../data/corpora/animais/https:--meusanimais_com_br-como-educar-o-seu-cao-para-morder-os-brinquedos-dele-e-nao-os-outros-objetos-da-casa-.txt\n",
      "../data/corpora/animais/https:--meusanimais_com_br-4-dicas-para-construir-uma-casinha-de-cachorro-no-jardim-.txt\n",
      "../data/corpora/animais/https:--meusanimais_com_br-outono-aproveite-para-brincar-com-seu-cao-nas-folhas-.txt\n",
      "../data/corpora/animais/https:--meusanimais_com_br-dicas-para-brincar-com-seu-coelho-.txt\n",
      "\n",
      "documentos similares ao documento:  ../data/corpora/games/https:--www_techtudo_com_br-listas-2019-04-farming-simulator-veja-evolucao-do-jogo-de-fazenda-que-e-sucesso_ghtml.txt\n",
      "../data/corpora/games/https:--www_techtudo_com_br-tudo-sobre-assassins-creed-2_html.txt\n",
      "../data/corpora/games/https:--www_techtudo_com_br-noticias-2018-12-brawl-stars-jogo-da-supercell-e-nova-promessa-dos-esports-entenda_ghtml.txt\n",
      "../data/corpora/animais/https:--meusanimais_com_br-o-orangotango-de-sumatra-.txt\n",
      "../data/corpora/games/https:--www_techtudo_com_br-listas-2019-03-fortnite-veja-cinco-easter-eggs-do-jogo-da-epic-games_ghtml.txt\n",
      "../data/corpora/games/https:--www_techtudo_com_br-tudo-sobre-nintendo-switch_html.txt\n",
      "\n",
      "documentos similares ao documento:  ../data/corpora/animais/https:--meusanimais_com_br-8-peixes-de-agua-doce-.txt\n",
      "../data/corpora/animais/https:--meusanimais_com_br-laperm-um-gatinho-de-pelos-encaracolados-.txt\n",
      "../data/corpora/animais/https:--meusanimais_com_br-como-se-tornar-um-guarda-florestal-.txt\n",
      "../data/corpora/animais/https:--meusanimais_com_br-7-racas-de-gatos-com-pelos-longos-?utm_medium=post&utm_source=website&utm_campaign=featured_post.txt\n",
      "../data/corpora/animais/https:--meusanimais_com_br-voce-conhece-o-espetacular-bullmastiff-.txt\n",
      "../data/corpora/animais/https:--meusanimais_com_br-o-azul-russo-realeza-felina-.txt\n"
     ]
    }
   ],
   "source": [
    "#numero de documentos similares que deseja procurar\n",
    "n_similar = 5\n",
    "\n",
    "#posicao do documento na lista all_documentos que deseja procurar documentos similares\n",
    "n_doc = 50\n",
    "n_doc1 = 950\n",
    "n_doc2 = 498\n",
    "\n",
    "print(\"\\ndocumentos similares ao documento: \", all_files[n_doc])\n",
    "similar_docs = d2vmodel.docvecs.most_similar(n_doc, topn=n_similar)\n",
    "for doc_num in similar_docs:\n",
    "    num_doc = int(doc_num[0])\n",
    "    print(all_files[num_doc])\n",
    "    \n",
    "print(\"\\ndocumentos similares ao documento: \", all_files[n_doc1])\n",
    "similar_docs = d2vmodel.docvecs.most_similar(n_doc1, topn=n_similar)\n",
    "for doc_num in similar_docs:\n",
    "    num_doc = int(doc_num[0])\n",
    "    print(all_files[num_doc])\n",
    "\n",
    "print(\"\\ndocumentos similares ao documento: \", all_files[n_doc2])\n",
    "similar_docs = d2vmodel.docvecs.most_similar(n_doc2, topn=n_similar)\n",
    "for doc_num in similar_docs:\n",
    "    num_doc = int(doc_num[0])\n",
    "    print(all_files[num_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
